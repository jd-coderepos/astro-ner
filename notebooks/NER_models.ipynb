{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLzi5t63SuLc"
      },
      "source": [
        "### Installing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-sX7rXLGlaC"
      },
      "outputs": [],
      "source": [
        "!pip install lightning transformers sentencepiece protobuf evaluate seqeval tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laY3QxjDS5qB"
      },
      "source": [
        "### Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DQwiuOh4GZrA"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from transformers import AdamW, MT5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoModel, AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning import Trainer\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCSY2iuYTCXV"
      },
      "source": [
        "### Pytorch dataset class\n",
        "Pytorch dataset class to manage and format our custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LoQpJS2nHKST"
      },
      "outputs": [],
      "source": [
        "class NERDataset(Dataset):\n",
        "  def __init__(self, data_json, tokenizer, max_len=512):\n",
        "    self.data_json = data_json\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "    self.tokenizer.max_length = max_len\n",
        "    self.tokenizer.model_max_length = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_json)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #Extracting the paper title\n",
        "    text = self.data_json[index]['title']\n",
        "\n",
        "    #Label is formatted as: [Tag:Value;Tag:Value...]\n",
        "    label = ';'.join([':'.join([annotation['label'], annotation['text']]) for annotation in self.data_json[index]['annotations']])\n",
        "\n",
        "    #Tokenizing the title with model's predefined tokenizer\n",
        "    source_encoding = self.tokenizer(text, max_length=self.max_len, padding=\"max_length\", truncation=True,\n",
        "                                      return_attention_mask=True, add_special_tokens=True, return_tensors=\"pt\")\n",
        "\n",
        "    #Tokenizing the formatted label with model's predefined tokenizer\n",
        "    target_encoding = self.tokenizer(label, max_length=self.max_len, padding=\"max_length\", truncation=True,\n",
        "                                return_attention_mask=True, add_special_tokens=True, return_tensors=\"pt\")\n",
        "\n",
        "    #Replacing padded 0s with -100 so that pytorch can ignore while training\n",
        "    label_encoding = target_encoding['input_ids']\n",
        "    label_encoding[label_encoding == 0] = -100\n",
        "\n",
        "    return dict(\n",
        "        text = text,\n",
        "        label = label,\n",
        "        input_ids = source_encoding['input_ids'].flatten(),\n",
        "        attention_mask = source_encoding['attention_mask'].flatten(),\n",
        "        label_encoding = label_encoding.flatten()\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NERDatasetGPT(Dataset):\n",
        "  def __init__(self, data_json, tokenizer, max_len=512):\n",
        "    self.data_json = data_json\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "    self.tokenizer.max_length = max_len\n",
        "    self.tokenizer.model_max_length = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_json)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #Extracting the paper title\n",
        "    text_group = re.search('```(.+?)```', self.data_json[index]['prompt'])\n",
        "    text = text_group.group(1) if text_group else ''\n",
        "\n",
        "    #Label is formatted as: [Tag:Value;Tag:Value...]\n",
        "    label = re.sub(': ', ':', self.data_json[index]['completion'].strip(\" #{}'\"))\n",
        "    label = re.sub(\"'\", '', label)\n",
        "    label = ';'.join([annot.strip() for annot in label.split(',')])\n",
        "\n",
        "    #Tokenizing the title with model's predefined tokenizer\n",
        "    source_encoding = self.tokenizer(text, max_length=self.max_len, padding=\"max_length\", truncation=True,\n",
        "                                      return_attention_mask=True, add_special_tokens=True, return_tensors=\"pt\")\n",
        "\n",
        "    #Tokenizing the formatted label with model's predefined tokenizer\n",
        "    target_encoding = self.tokenizer(label, max_length=self.max_len, padding=\"max_length\", truncation=True,\n",
        "                                return_attention_mask=True, add_special_tokens=True, return_tensors=\"pt\")\n",
        "\n",
        "    #Replacing padded 0s with -100 so that pytorch can ignore while training\n",
        "    label_encoding = target_encoding['input_ids']\n",
        "    label_encoding[label_encoding == 0] = -100\n",
        "\n",
        "    return dict(\n",
        "        text = text,\n",
        "        label = label,\n",
        "        input_ids = source_encoding['input_ids'].flatten(),\n",
        "        attention_mask = source_encoding['attention_mask'].flatten(),\n",
        "        label_encoding = label_encoding.flatten()\n",
        "    )"
      ],
      "metadata": {
        "id": "PCPJVlC7yilr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cPNziS7TWWZ"
      },
      "source": [
        "### Pytorch Lightning Data Module\n",
        "A class that encapsulates all the steps needed to process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aKNcdvaZHaKV"
      },
      "outputs": [],
      "source": [
        "class NERDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, batch_size, train_dataset, test_dataset, num_workers = 2):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.train_dataset = train_dataset\n",
        "    self.test_dataset = test_dataset\n",
        "    self.prepare_data_per_node = True\n",
        "    self.num_workers = num_workers\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.test_dataset, batch_size=1, num_workers=self.num_workers)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_dataset, batch_size=1, num_workers=self.num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arEg3PdiTgCO"
      },
      "source": [
        "### Pytorch Lightning Module\n",
        "A pytorch lightning encapsulation to manage, train and test our models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dy9eFyACIb5g"
      },
      "outputs": [],
      "source": [
        "class NERModel(pl.LightningModule):\n",
        "  def __init__(self, model, model_name, learning_rate):\n",
        "    super().__init__()\n",
        "    self.model = model.from_pretrained(model_name)\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels):\n",
        "    return self.model(input_ids = input_ids, attention_mask = attention_mask, labels = labels)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    label_encoding = batch['label_encoding']\n",
        "    loss = self(input_ids, attention_mask, label_encoding).loss\n",
        "    self.log('Training Loss', loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    label_encoding = batch['label_encoding']\n",
        "    loss = self(input_ids, attention_mask, label_encoding).loss\n",
        "    self.log('Validation Loss', loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    label_encoding = batch['label_encoding']\n",
        "    loss = self(input_ids, attention_mask, label_encoding).loss\n",
        "    self.log('Test Loss', loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return AdamW(self.parameters(), lr=self.learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is-acch3ya6E"
      },
      "source": [
        "### Function to train the model of given type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gdRzFh6f95XK"
      },
      "outputs": [],
      "source": [
        "def train_model(train_dataset, test_dataset, params):\n",
        "  #Initializing model specific tokenizer\n",
        "  tokenizer = AutoTokenizer.from_pretrained(params['model_name'])\n",
        "\n",
        "  #Initializing the train and test dataset\n",
        "  NER_train = NERDatasetGPT(train_dataset, tokenizer) if params['gpt_train_data'] else NERDataset(train_dataset, tokenizer)\n",
        "  NER_test = NERDataset(test_dataset, tokenizer)\n",
        "\n",
        "  #Encapsulating the train and test dataset with data module\n",
        "  NER_datamodule = NERDataModule(params['batch_size'], NER_train, NER_test, params['num_workers'])\n",
        "\n",
        "  #Initializing the NER model of specified type with parameters\n",
        "  model = NERModel(params['model'], params['model_name'], params['learning_rate'])\n",
        "\n",
        "  #Initializing the pytorch lightning trainer object to train our NER model\n",
        "  trainer = Trainer(max_epochs=params['epochs'], enable_progress_bar=True, accumulate_grad_batches=params['accumulate_grad_batches'])\n",
        "\n",
        "  #Training the model on the dataset\n",
        "  trainer.fit(model, datamodule=NER_datamodule)\n",
        "\n",
        "  #returning the trained NER model\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiU3xvlfIMx3"
      },
      "source": [
        "### Function to convert annotations in NER's IOB format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iPRUAv6XC2o6"
      },
      "outputs": [],
      "source": [
        "def generate_NER_label(input_text, target):\n",
        "  #Splitting the input title on spaces\n",
        "  input_text = re.sub(r'[:“”]', '', input_text)\n",
        "  input_text = input_text.split(' ')\n",
        "\n",
        "  #Initializing a list with 'O'\n",
        "  target_label = ['O']* len(input_text)\n",
        "\n",
        "  if ':' not in target or ';' not in target:\n",
        "    return target_label\n",
        "\n",
        "  #Splitting the label into multiple annotations\n",
        "  target = target.split(';')\n",
        "\n",
        "  #Iterating over all the annotations\n",
        "  for tar in target:\n",
        "    #Splitting the label into annotation type and value\n",
        "    annotation = tar.split(':')\n",
        "\n",
        "    #Checking if both tag and value are present\n",
        "    if len(annotation) < 2:\n",
        "        continue\n",
        "\n",
        "    #Saving the annotation type\n",
        "    suffix = annotation[0]\n",
        "    IOB_prefix = 'B-'\n",
        "\n",
        "    #Iterating over all words in the annotation value\n",
        "    for word in annotation[1].strip().split(' '):\n",
        "      try:\n",
        "        #Replacing the IOB value at the word index\n",
        "        target_label[input_text.index(word)] = IOB_prefix + suffix\n",
        "        IOB_prefix = 'I-'\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "  return target_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDysHmy2zcD0"
      },
      "source": [
        "### Function to evaluate the model on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "44MjJhPUDsFV"
      },
      "outputs": [],
      "source": [
        "def compute_metric(model, dataset, params):\n",
        "  #Putting the model in the evaluation mode\n",
        "  model.model.eval()\n",
        "\n",
        "  #Initializing model specific tokenizer\n",
        "  tokenizer = AutoTokenizer.from_pretrained(params['model_name'])\n",
        "\n",
        "  #Initializng lists to store true labels and predictions\n",
        "  true_labels = []\n",
        "  predictions = []\n",
        "\n",
        "  for sample in tqdm(dataset):\n",
        "    #Tokenizing the title with model's predefined tokenizer\n",
        "    source_encoding = tokenizer(sample['title'], max_length=params['max_length'], padding=\"max_length\", truncation=True,\n",
        "                                return_attention_mask=True, add_special_tokens=True, return_tensors=\"pt\")\n",
        "    #Generating the model's prediction on the input title\n",
        "    pred_ids = model.model.generate(input_ids = source_encoding['input_ids'], attention_mask = source_encoding['attention_mask'],\n",
        "                                    max_length = params['max_length'])\n",
        "\n",
        "    #Storing the true labels and model's prediction\n",
        "    true_labels.append(generate_NER_label(sample['title'], ';'.join([':'.join([annotation['label'], annotation['text']]) for annotation in sample['annotations']])))\n",
        "    predictions.append(generate_NER_label(sample['title'], [tokenizer.decode(pred_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for pred_id in pred_ids][0]))\n",
        "\n",
        "  #Evaluating the predictions\n",
        "  seqeval = evaluate.load('seqeval')\n",
        "  seqeval_val = seqeval.compute(predictions= predictions, references=true_labels)\n",
        "  return true_labels, predictions, seqeval_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHjpyLq_10Vf"
      },
      "source": [
        "### Model's training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ivXLetaRO9Vm"
      },
      "outputs": [],
      "source": [
        "params = dict(\n",
        "    model = MT5ForConditionalGeneration,\n",
        "    model_name = 'google/mt5-small',\n",
        "    test_size = 0.1,\n",
        "    batch_size = 2,\n",
        "    learning_rate = 3e-4,\n",
        "    epochs = 5,\n",
        "    accumulate_grad_batches = 4,\n",
        "    max_length = 512,\n",
        "    num_workers = 2,\n",
        "    gpt_train_data = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tY7DX0U2AKX"
      },
      "source": [
        "### Reading the dataset and doing train test splits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading the file with complete astrophysics dataset"
      ],
      "metadata": {
        "id": "Inj8BnQ7dn0O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WgREG5tCGigV"
      },
      "outputs": [],
      "source": [
        "with open('./astrophysics_entity_dataset.json', 'r') as json_data:\n",
        "    dataset = json.load(json_data)\n",
        "train_dataset, test_dataset = train_test_split(dataset, test_size=params['test_size'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading files containing train and test data used to for GPT finetuning"
      ],
      "metadata": {
        "id": "haAWAFRKdxbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./gpt3_finetuning_data.json', 'r') as gpt3_json_data:\n",
        "  train_dataset = json.load(gpt3_json_data)\n",
        "with open('./1500titles_human-annotators.json', 'r') as ha_json_data:\n",
        "  test_dataset = json.load(ha_json_data)"
      ],
      "metadata": {
        "id": "4nbl7mCyxBxZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ids = [td['id'] for td in test_dataset]\n",
        "train_dataset = [annotation for annotation in dataset if annotation['id'] not in test_ids]"
      ],
      "metadata": {
        "id": "uqehKc6r4d2O"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZJ_0PsE2J1h"
      },
      "source": [
        "### MT5 NER model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7JTqrr1Uzef"
      },
      "outputs": [],
      "source": [
        "mt5_model = train_model(train_dataset, test_dataset, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9uA8QrqdKU1"
      },
      "outputs": [],
      "source": [
        "mt5_true, mt5_pred, mt5_metric_result = compute_metric(mt5_model, test_dataset, params)\n",
        "mt5_metric_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5fen_qy2RmJ"
      },
      "source": [
        "### FLAN-T5 NER model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qmoJLF1AuM3I"
      },
      "outputs": [],
      "source": [
        "params['model'] = AutoModelForSeq2SeqLM\n",
        "params['model_name'] = 'google/flan-t5-small'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MtzicN02tIO"
      },
      "outputs": [],
      "source": [
        "flant5_model = train_model(train_dataset, test_dataset, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLpuFWWAdMPb"
      },
      "outputs": [],
      "source": [
        "flant5_true, flant5_pred, flant5_metric_result = compute_metric(flant5_model, test_dataset, params)\n",
        "flant5_metric_result"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}